{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <p style=\"text-align:center\">\n",
    "        <img alt=\"phoenix logo\" src=\"https://raw.githubusercontent.com/Arize-ai/phoenix-assets/9e6101d95936f4bd4d390efc9ce646dc6937fb2d/images/socal/github-large-banner-phoenix.jpg\" width=\"1000\"/>\n",
    "        <br>\n",
    "        <br>\n",
    "        <a href=\"https://docs.arize.com/phoenix/\">Docs</a>\n",
    "        |\n",
    "        <a href=\"https://github.com/Arize-ai/phoenix\">GitHub</a>\n",
    "        |\n",
    "        <a href=\"https://join.slack.com/t/arize-ai/shared_invite/zt-1px8dcmlf-fmThhDFD_V_48oU7ALan4Q\">Community</a>\n",
    "    </p>\n",
    "</center>\n",
    "<h1 align=\"center\">CrewAI Agents: Orchestrator-Worker Patterns</center>\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, weâ€™ll build a CrewAI multi-agent system using the Orchestratorâ€“Worker pattern. This is a powerful approach for dynamically breaking down complex tasks into smaller subtasks, assigning them to specialized agents, and combining their outputs into a cohesive result.\n",
    "\n",
    "This pattern is especially useful when the subtasks arenâ€™t known in advanceâ€”like drafting a multi-section report, writing modular code, or conducting structured research. The orchestrator agent takes charge of planning and delegating, while the worker agents each focus on completing their assigned part.\n",
    "\n",
    "Weâ€™ll also integrate Phoenix to trace and debug the orchestration process. With Phoenix, you can see how the orchestrator generated tasks, how each worker executed its role, and how their outputs were assembled into the final result.\n",
    "\n",
    "By the end of this notebook, youâ€™ll learn how to:\n",
    "\n",
    "- Define and create a crew of specialized agents.\n",
    "\n",
    "- Dynamically plan and delegate subtasks across workers.\n",
    "\n",
    "- Run and evaluate the crewâ€™s performance on a given task.\n",
    "\n",
    "- Trace and visualize orchestration flows using Phoenix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this tutorial, you'll need:\n",
    "\n",
    "*   OpenAI API key (https://openai.com/)\n",
    "*   Serper API key (https://serper.dev/)\n",
    "*   Free Phoenix Cloud account and API key (https://app.phoenix.arize.com/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5-gPdVmIndw9"
   },
   "source": [
    "# Set up Keys and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q arize-phoenix opentelemetry-sdk opentelemetry-exporter-otlp crewai crewai_tools openinference-instrumentation-crewai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "if \"SERPER_API_KEY\" not in os.environ:\n",
    "    os.environ[\"SERPER_API_KEY\"] = getpass(\"ðŸ”‘ Enter your Serper API key: \")\n",
    "\n",
    "if \"PHOENIX_API_KEY\" not in os.environ:\n",
    "    os.environ[\"PHOENIX_API_KEY\"] = getpass(\"ðŸ”‘ Enter your Phoenix API key: \")\n",
    "\n",
    "if \"PHOENIX_COLLECTOR_ENDPOINT\" not in os.environ:\n",
    "    os.environ[\"PHOENIX_COLLECTOR_ENDPOINT\"] = getpass(\"ðŸ”‘ Enter your Phoenix Collector Endpoint\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r9X87mdGnpbc"
   },
   "source": [
    "## Configure Tracing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from phoenix.otel import register\n",
    "\n",
    "project_name = \"crewai-agents-orchestrator-workers\"\n",
    "tracer_provider = register(project_name=project_name, auto_instrument=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define your Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai import Agent, Crew, Task\n",
    "\n",
    "# Define worker agents\n",
    "trend_researcher = Agent(\n",
    "    role=\"AI Trend Researcher\",\n",
    "    goal=\"Analyze current advancements in AI\",\n",
    "    backstory=\"Expert in tracking and analyzing new trends in artificial intelligence.\",\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "policy_analyst = Agent(\n",
    "    role=\"AI Policy Analyst\",\n",
    "    goal=\"Examine the implications of AI regulations and governance\",\n",
    "    backstory=\"Tracks AI policy developments across governments and organizations.\",\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "risk_specialist = Agent(\n",
    "    role=\"AI Risk Specialist\",\n",
    "    goal=\"Identify potential risks in frontier AI development\",\n",
    "    backstory=\"Focuses on safety, alignment, and misuse risks related to advanced AI.\",\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "synthesizer = Agent(\n",
    "    role=\"Synthesis Writer\",\n",
    "    goal=\"Summarize all findings into a final cohesive report\",\n",
    "    backstory=\"Expert at compiling research insights into executive-level narratives.\",\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "orchestrator = Agent(\n",
    "    role=\"Orchestrator\",\n",
    "    goal=(\n",
    "        \"Your job is to delegate research and writing tasks to the correct coworker using the 'Delegate work to coworker' tool.\\n\"\n",
    "        \"For each task you assign, you MUST call the tool with the following JSON input:\\n\\n\"\n",
    "        \"{\\n\"\n",
    "        '  \"task\": \"Short summary of the task to do (plain string)\",\\n'\n",
    "        '  \"context\": \"Why this task is important or part of the report (plain string)\",\\n'\n",
    "        '  \"coworker\": \"One of: AI Trend Researcher, AI Policy Analyst, AI Risk Specialist, Synthesis Writer\"\\n'\n",
    "        \"}\\n\\n\"\n",
    "        \"IMPORTANT:\\n\"\n",
    "        \"- Do NOT format 'task' or 'context' as dictionaries.\\n\"\n",
    "        \"- Do NOT include types or nested descriptions.\\n\"\n",
    "        \"- Only use plain strings for both.\\n\"\n",
    "        \"- Call the tool multiple times, one per coworker.\"\n",
    "    ),\n",
    "    backstory=\"You are responsible for assigning each part of an AI report to the right specialist.\",\n",
    "    verbose=True,\n",
    "    allow_delegation=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define your Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the initial task only for the orchestrator\n",
    "initial_task = Task(\n",
    "    description=\"Create an AI trends report. It should include recent innovations, policy updates, and safety risks. Then synthesize it into a unified summary.\",\n",
    "    expected_output=\"Assign subtasks via the DelegateWorkTool and return a final report.\",\n",
    "    agent=orchestrator,\n",
    ")\n",
    "\n",
    "# Set up the crew (no hierarchical process needed with delegation tools)\n",
    "crew = Crew(\n",
    "    agents=[trend_researcher, policy_analyst, risk_specialist, synthesizer],\n",
    "    tasks=[initial_task],\n",
    "    manager_agent=orchestrator,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# Run the full workflow\n",
    "result = crew.kickoff()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent Evaluation\n",
    "\n",
    "Here, we will evaluate the agentâ€™s trajectory. This means checking whether the sequence of steps it took was logical, efficient, and aligned with completing the userâ€™s request. Then, we will log those results back to Phoenix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from phoenix.client import AsyncClient\n",
    "\n",
    "px_client = AsyncClient()\n",
    "df = await px_client.spans.get_spans_dataframe(project_name=project_name)\n",
    "\n",
    "trace_df = df.groupby(\"context.trace_id\").agg(\n",
    "    {\n",
    "        \"attributes.input.value\": \"first\",\n",
    "        \"attributes.output.value\": lambda x: \" \".join(x.dropna()),\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "def extract_input_content(input_value):\n",
    "    try:\n",
    "        if pd.isna(input_value) or input_value is None:\n",
    "            return None\n",
    "\n",
    "        # JSON string\n",
    "        if isinstance(input_value, str):\n",
    "            import json\n",
    "\n",
    "            try:\n",
    "                parsed = json.loads(input_value)\n",
    "                inputs = parsed.get(\"messages\", [])\n",
    "                if isinstance(inputs, list) and len(inputs) > 0:\n",
    "                    return inputs[0].get(\"content\")\n",
    "                return None\n",
    "            except Exception:\n",
    "                return None\n",
    "\n",
    "        return input_value\n",
    "\n",
    "    except (AttributeError, TypeError, KeyError):\n",
    "        return input_value\n",
    "\n",
    "\n",
    "# Apply function row by row\n",
    "trace_df[\"attributes.input.value\"] = trace_df[\"attributes.input.value\"].apply(extract_input_content)\n",
    "trace_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAJECTORY_PERFORMANCE_PROMPT = \"\"\"\n",
    "You are a helpful AI bot that checks whether an AI agent's internal trajectory is accurate and effective.\n",
    "\n",
    "You will be given:\n",
    "1. You will be given an input query from a user that the agent responded to\n",
    "2. The agent's actual trajectory of tool calls and responses\n",
    "\n",
    "An accurate trajectory:\n",
    "- Progresses logically from step to step\n",
    "- Follows the golden trajectory where reasonable\n",
    "- Shows a clear path toward completing a goal\n",
    "- Is reasonably efficient (doesn't take unnecessary detours)\n",
    "\n",
    "##\n",
    "\n",
    "User Query:\n",
    "{attributes.input.value}\n",
    "\n",
    "Trajectory:\n",
    "{attributes.output.value}\n",
    "\n",
    "##\n",
    "\n",
    "Your response must be a single string, either `correct` or `incorrect`, and must not include any additional text.\n",
    "\n",
    "- Respond with `correct` if the agent's trajectory adheres to the rubric and accomplishes the task effectively.\n",
    "- Respond with `incorrect` if the trajectory is confusing, misaligned with the goal, inefficient, or does not accomplish the task.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from phoenix.evals import OpenAIModel, llm_classify\n",
    "from phoenix.trace import suppress_tracing\n",
    "\n",
    "model = OpenAIModel(\n",
    "    api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.0,\n",
    ")\n",
    "\n",
    "rails = [\"correct\", \"incorrect\"]\n",
    "\n",
    "with suppress_tracing():\n",
    "    eval_results = llm_classify(\n",
    "        dataframe=trace_df,\n",
    "        template=TRAJECTORY_PERFORMANCE_PROMPT,\n",
    "        model=model,\n",
    "        rails=rails,\n",
    "        provide_explanation=True,\n",
    "        verbose=False,\n",
    "        concurrency=20,\n",
    "    )\n",
    "\n",
    "eval_results[\"score\"] = eval_results[\"label\"].apply(lambda x: 1 if x == \"correct\" else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_spans = df[df[\"parent_id\"].isna()][[\"context.trace_id\", \"context.span_id\"]]\n",
    "eval_results = eval_results[[\"score\", \"label\", \"explanation\"]]\n",
    "\n",
    "trajectory_eval_df = pd.merge(trace_df, eval_results, left_index=True, right_index=True, how=\"left\")\n",
    "\n",
    "trajectory_eval_df = pd.merge(\n",
    "    trajectory_eval_df.reset_index(), root_spans, on=\"context.trace_id\", how=\"left\"\n",
    ").set_index(\"context.span_id\", drop=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log Evals to Phoenix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await px_client.annotations.log_span_annotations_dataframe(\n",
    "    dataframe=trajectory_eval_df,\n",
    "    annotation_name=\"TRAJECTORY PERFORMANCE\",\n",
    "    annotator_kind=\"LLM\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fH0uVMgxpLql"
   },
   "source": [
    "# View Final Results in Phoenix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Evals](https://storage.googleapis.com/arize-phoenix-assets/assets/images/crewai-agents-orchestrator.png)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
