{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <p style=\"text-align:center\">\n",
    "        <img alt=\"phoenix logo\" src=\"https://storage.googleapis.com/arize-phoenix-assets/assets/phoenix-logo-light.svg\" width=\"200\"/>\n",
    "        <br>\n",
    "        <a href=\"https://arize.com/docs/phoenix/\">Docs</a>\n",
    "        |\n",
    "        <a href=\"https://github.com/Arize-ai/phoenix\">GitHub</a>\n",
    "        |\n",
    "        <a href=\"https://arize-ai.slack.com/join/shared_invite/zt-2w57bhem8-hq24MB6u7yE_ZF_ilOYSBw#/shared-invite/email\">Community</a>\n",
    "    </p>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SUknhuHKyc-E"
   },
   "source": [
    "# <center>OpenAI Agents: Orchestrator-Worker Patterns</center>\n",
    "\n",
    "A starter guide for building an agent loop using the `openai-agents` library.\n",
    "\n",
    "This pattern uses orchestators and workers. The orchestrator chooses which worker to use for a specific sub-task. The worker attempts to complete the sub-task and return a result. The orchestrator then uses the result to choose the next worker to use until a final result is returned.\n",
    "\n",
    "In the following example, we'll build an agent which creates a portfolio of stocks and ETFs based on a user's investment strategy.\n",
    "1.  **Orchestrator:** Chooses which worker to use based on the user's investment strategy.\n",
    "2.  **Research Agent:** Searches the web for information about stocks and ETFs that could support the user's investment strategy.\n",
    "3.  **Evaluation Agent:** Evaluates the research report and provides feedback on what data is missing.\n",
    "4.  **Portfolio Agent:** Creates a portfolio of stocks and ETFs based on the research report.\n",
    "\n",
    "‚ö†Ô∏è You'll need a [free Phoenix Cloud](https://app.arize.com/auth/phoenix/login) account and an OpenAI Key for this tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n69HR7eJswNt"
   },
   "source": [
    "### Install Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install base libraries for OpenAI\n",
    "%pip install -qq openai openai-agents\n",
    "\n",
    "# Install libraries for OpenInference/OpenTelemetry tracing\n",
    "%pip install -qqq arize-phoenix openinference-instrumentation-openai-agents openinference-instrumentation-openai openinference-instrumentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jQnyEnJisyn3"
   },
   "source": [
    "### Setup Keys\n",
    "\n",
    "Add your OpenAI API key to the environment variable `OPENAI_API_KEY`.\n",
    "\n",
    "Copy your Phoenix `API_KEY` from your settings page at [app.phoenix.arize.com](https://app.phoenix.arize.com)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "if \"OPENAI_API_KEY\" not in os.environ:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass(\"üîë Enter your OpenAI API key: \")\n",
    "\n",
    "if \"PHOENIX_API_KEY\" not in os.environ:\n",
    "    os.environ[\"PHOENIX_API_KEY\"] = getpass(\"üîë Enter your Phoenix API key: \")\n",
    "\n",
    "if \"PHOENIX_COLLECTOR_ENDPOINT\" not in os.environ:\n",
    "    os.environ[\"PHOENIX_COLLECTOR_ENDPOINT\"] = getpass(\"üîë Enter your Phoenix Collector Endpoint\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kfid5cE99yN5"
   },
   "source": [
    "### Setup Tracing and Phoenix Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from phoenix.otel import register\n",
    "\n",
    "PROJECT_NAME = \"openai-agents-orchestrator-workers\"\n",
    "tracer_provider = register(project_name=PROJECT_NAME, auto_instrument=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from phoenix.client import AsyncClient\n",
    "\n",
    "px_client = AsyncClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from textwrap import dedent\n",
    "from typing import Literal\n",
    "\n",
    "from agents import Agent, Runner, TResponseInputItem, WebSearchTool\n",
    "from agents.model_settings import ModelSettings\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class PortfolioItem(BaseModel):\n",
    "    ticker: str = Field(description=\"The ticker of the stock or ETF.\")\n",
    "    allocation: float = Field(\n",
    "        description=\"The percentage allocation of the ticker in the portfolio. The sum of all allocations should be 100.\"\n",
    "    )\n",
    "    reason: str = Field(description=\"The reason why this ticker is included in the portfolio.\")\n",
    "\n",
    "\n",
    "class Portfolio(BaseModel):\n",
    "    tickers: list[PortfolioItem] = Field(\n",
    "        description=\"A list of tickers that could support the user's stated investment strategy.\"\n",
    "    )\n",
    "\n",
    "\n",
    "class EvaluationFeedback(BaseModel):\n",
    "    feedback: str = Field(\n",
    "        description=\"What data is missing in order to create a portfolio of stocks and ETFs based on the user's investment strategy.\"\n",
    "    )\n",
    "    score: Literal[\"pass\", \"needs_improvement\", \"fail\"] = Field(\n",
    "        description=\"A score on the research report. Pass if you have at least 5 tickers with data that supports the user's investment strategy to create a portfolio, needs_improvement if you do not have enough supporting data, and fail if you have no tickers.\"\n",
    "    )\n",
    "\n",
    "\n",
    "evaluation_agent = Agent(\n",
    "    name=\"Evaluation Agent\",\n",
    "    instructions=dedent(\n",
    "        \"\"\"You are a senior financial analyst. You will be provided with a stock research report with positive and negative catalysts. Your task is to evaluate the report and provide feedback on what to improve.\"\"\"\n",
    "    ),\n",
    "    model=\"gpt-4.1\",\n",
    "    output_type=EvaluationFeedback,\n",
    ")\n",
    "\n",
    "portfolio_agent = Agent(\n",
    "    name=\"Portfolio Agent\",\n",
    "    instructions=dedent(\n",
    "        \"\"\"You are a senior financial analyst. You will be provided with a stock research report. Your task is to create a portfolio of stocks and ETFs that could support the user's stated investment strategy. Include facts and data from the research report in the stated reasons for the portfolio allocation.\"\"\"\n",
    "    ),\n",
    "    model=\"o4-mini\",\n",
    "    output_type=Portfolio,\n",
    ")\n",
    "\n",
    "research_agent = Agent(\n",
    "    name=\"FinancialSearchAgent\",\n",
    "    instructions=dedent(\n",
    "        \"\"\"You are a research assistant specializing in financial topics. Given a stock ticker, use web search to retrieve up‚Äëto‚Äëdate context and produce a short summary of at most 50 words. Focus on key numbers, events, or quotes that will be useful to a financial analyst.\"\"\"\n",
    "    ),\n",
    "    model=\"gpt-4.1\",\n",
    "    tools=[WebSearchTool()],\n",
    "    model_settings=ModelSettings(tool_choice=\"required\", parallel_tool_calls=True),\n",
    ")\n",
    "\n",
    "orchestrator_agent = Agent(\n",
    "    name=\"Routing Agent\",\n",
    "    instructions=dedent(\"\"\"You are a senior financial analyst. You are trying to create a portfolio based on my stated investment strategy. Your task is to handoff to the appropriate agent or tool.\n",
    "\n",
    "    First, handoff to the research_agent to give you a report on stocks and ETFs that could support the user's stated investment strategy.\n",
    "    Then, handoff to the evaluation_agent to give you a score on the research report. If the evaluation_agent returns a needs_improvement or fail, continue using the research_agent to gather more information.\n",
    "    Once the evaluation_agent returns a pass, handoff to the portfolio_agent to create a portfolio.\"\"\"),\n",
    "    model=\"gpt-4.1\",\n",
    "    handoffs=[\n",
    "        research_agent,\n",
    "        evaluation_agent,\n",
    "        portfolio_agent,\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run our Workflow! \n",
    "\n",
    "Run the cell below and enter your investment strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from uuid import uuid4\n",
    "\n",
    "import opentelemetry.trace as trace\n",
    "from openinference.semconv.trace import SpanAttributes\n",
    "\n",
    "tracer = trace.get_tracer(\"openai-agents-orchestrator-workers\")\n",
    "\n",
    "MAX_PASSES = 10\n",
    "PASS_TIMEOUT = 500\n",
    "\n",
    "\n",
    "async def run_agent_workflow():\n",
    "    user_input = input(\"Enter your investment strategy: \")\n",
    "    input_items: list[TResponseInputItem] = [{\"content\": user_input, \"role\": \"user\"}]\n",
    "\n",
    "    with tracer.start_as_current_span(\n",
    "        \"Agent workflow\",\n",
    "        attributes={\n",
    "            SpanAttributes.OPENINFERENCE_SPAN_KIND: \"agent\",\n",
    "            SpanAttributes.INPUT_VALUE: user_input,\n",
    "            SpanAttributes.SESSION_ID: str(uuid4()),\n",
    "        },\n",
    "    ) as root_span:\n",
    "        passes = 0\n",
    "        while passes < MAX_PASSES:\n",
    "            try:\n",
    "                orchestrator = await asyncio.wait_for(\n",
    "                    Runner.run(orchestrator_agent, input_items),\n",
    "                    timeout=PASS_TIMEOUT,\n",
    "                )\n",
    "            except asyncio.TimeoutError:\n",
    "                print(f\"Pass {passes + 1} hit the {PASS_TIMEOUT}s timeout‚Äîaborting.\")\n",
    "                break\n",
    "\n",
    "            out = orchestrator.final_output\n",
    "            pprint(out)\n",
    "\n",
    "            if isinstance(out, Portfolio):\n",
    "                break\n",
    "\n",
    "            input_items = orchestrator.to_input_list()\n",
    "            passes += 1\n",
    "\n",
    "        root_span.set_attribute(SpanAttributes.OUTPUT_VALUE, str(out))\n",
    "\n",
    "    print(\"AGENT COMPLETE\")\n",
    "\n",
    "\n",
    "await run_agent_workflow()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the Agent\n",
    "\n",
    "Here, we will evaluate the agent‚Äôs trajectory. This means checking whether the sequence of steps it took was logical, efficient, and aligned with completing the user‚Äôs request. Then, we will log those results back to Phoenix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = await px_client.spans.get_spans_dataframe(project_name=PROJECT_NAME)\n",
    "\n",
    "trace_df = df.groupby(\"context.trace_id\").agg(\n",
    "    {\n",
    "        \"attributes.input.value\": \"first\",\n",
    "        \"attributes.output.value\": lambda x: \" \".join(x.dropna()),\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "def extract_input_content(input_value):\n",
    "    try:\n",
    "        if pd.isna(input_value) or input_value is None:\n",
    "            return None\n",
    "\n",
    "        # JSON string\n",
    "        if isinstance(input_value, str):\n",
    "            import json\n",
    "\n",
    "            try:\n",
    "                parsed = json.loads(input_value)\n",
    "                inputs = parsed.get(\"input\", [])\n",
    "                if isinstance(inputs, list) and len(inputs) > 0:\n",
    "                    return inputs[0].get(\"content\")\n",
    "                return None\n",
    "            except Exception:\n",
    "                return None\n",
    "\n",
    "        return None\n",
    "\n",
    "    except (AttributeError, TypeError, KeyError):\n",
    "        return None\n",
    "\n",
    "\n",
    "# Apply function row by row\n",
    "trace_df[\"attributes.input.value\"] = trace_df[\"attributes.input.value\"].apply(extract_input_content)\n",
    "trace_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAJECTORY_PERFORMANCE_PROMPT = \"\"\"\n",
    "You are a helpful AI bot that checks whether an AI agent's internal trajectory is accurate and effective.\n",
    "\n",
    "You will be given:\n",
    "1. You will be given an input query from a user that the agent responded to\n",
    "2. The agent's actual trajectory of tool calls and responses\n",
    "\n",
    "An accurate trajectory:\n",
    "- Progresses logically from step to step\n",
    "- Follows the golden trajectory where reasonable\n",
    "- Shows a clear path toward completing a goal\n",
    "- Is reasonably efficient (doesn't take unnecessary detours)\n",
    "\n",
    "##\n",
    "\n",
    "User Query:\n",
    "{attributes.input.value}\n",
    "\n",
    "Trajectory:\n",
    "{attributes.output.value}\n",
    "\n",
    "##\n",
    "\n",
    "Your response must be a single string, either `correct` or `incorrect`, and must not include any additional text.\n",
    "\n",
    "- Respond with `correct` if the agent's trajectory adheres to the rubric and accomplishes the task effectively.\n",
    "- Respond with `incorrect` if the trajectory is confusing, misaligned with the goal, inefficient, or does not accomplish the task.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from phoenix.evals import OpenAIModel, llm_classify\n",
    "from phoenix.trace import suppress_tracing\n",
    "\n",
    "model = OpenAIModel(\n",
    "    api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.0,\n",
    ")\n",
    "\n",
    "rails = [\"correct\", \"incorrect\"]\n",
    "\n",
    "with suppress_tracing():\n",
    "    eval_results = llm_classify(\n",
    "        dataframe=trace_df,\n",
    "        template=TRAJECTORY_PERFORMANCE_PROMPT,\n",
    "        model=model,\n",
    "        rails=rails,\n",
    "        provide_explanation=True,\n",
    "        verbose=False,\n",
    "        concurrency=20,\n",
    "    )\n",
    "\n",
    "eval_results[\"score\"] = eval_results[\"label\"].apply(lambda x: 1 if x == \"correct\" else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_spans = df[df[\"parent_id\"].isna()][[\"context.trace_id\", \"context.span_id\"]]\n",
    "eval_results = eval_results[[\"score\", \"label\", \"explanation\"]]\n",
    "\n",
    "trajectory_eval_df = pd.merge(trace_df, eval_results, left_index=True, right_index=True, how=\"left\")\n",
    "\n",
    "trajectory_eval_df = pd.merge(\n",
    "    trajectory_eval_df.reset_index(), root_spans, on=\"context.trace_id\", how=\"left\"\n",
    ").set_index(\"context.span_id\", drop=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log Evals to Phoenix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await px_client.annotations.log_span_annotations_dataframe(\n",
    "    dataframe=trajectory_eval_df,\n",
    "    annotation_name=\"TRAJECTORY PERFORMANCE\",\n",
    "    annotator_kind=\"LLM\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View Results in Phoenix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When viewing the traces in Phoenix, you can see how the agent delegated subtasks to specialized agents step-by-step. The trace shows the order in which each agent responded, making it easy to verify the flow from flight planning to hotel booking to activity suggestions. \n",
    "\n",
    "The agent trajectory evaluation is tied to the root span of the trace, allowing you to assess the overall sequence of steps. \n",
    "\n",
    "![Results](https://storage.googleapis.com/arize-phoenix-assets/assets/images/openai-agentframework-eval.png)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
